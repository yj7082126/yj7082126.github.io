---
layout: about
title: about
permalink: /
subtitle: <a href='assets/pdf/Patrick_CV.pdf'>[CV]</a> <a href='https://twitter.com/Patrick920728'>[Twitter]</a> <a href='https://www.linkedin.com/in/patrickkwon/'>[Linkedin]</a> <a href='https://scholar.google.com/citations?user=XRKA-DkAAAAJ&hl=ko'>[Google Scholar]</a> <a href='https://github.com/yj7082126'>[Github]</a>

profile:
  align: right
  image: profile_pic.jpg
  image_circular: true # crops the image to make it circular

news: true  # includes a list of news items
latest_posts: true  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---
 
I am a first-year research assistant at the [Center for Research in Computer Vision, UCF](https://www.crcv.ucf.edu/), working with [Dr. Chen Chen](https://www.crcv.ucf.edu/chenchen/index.html). 
Previously, I worked as a full-time research scientist at [Naver Webtoon Corp.](https://webtoonscorp.com/en/) studying computer vision, graphics, and AI. I have also worked with Professor Hanbyul Joo and [SNU VCLab](https://jhugestar.github.io/) in solving 3D reconstruction and affordance problems.
I received my Master's degree at [Columbia University](https://datascience.columbia.edu/) studying machine learning and human-computer interaction within augmented reality.

My main research goal is in embedding human prior knowledge within generative AI systems. Specifically, I aspire to create AI systems that has a human level understanding towards visual context, which in turn will pave way for novel solutions in the field of computer vision. For instance, how can we aid video generation models to better understand human-object interaction? And how can we utilize such models in helping content creators and improving robotics systems?
These are just few of the questions I hope to discover answers for.
